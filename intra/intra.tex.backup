%intra.tex
%Par Guillaume Lahaie
%LAHG04077707
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Simple Sectioned Essay Template
% LaTeX Template
%
% This template has been downloaded from:
% http://www.latextemplates.com
%
% Note:
% The \lipsum[#] commands throughout this template generate dummy text
% to fill the template out. These commands should all be removed when 
% writing essay content.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[10.9pt]{article} % Default font size is 12pt, it can be changed here
\renewcommand{\familydefault}{\rmdefault}
\renewcommand{\thesubsection}{\alph{subsection}}

%Pour l'encodage avec accents
\usepackage[utf8]{inputenc}
\usepackage{longtable}
\usepackage{sidecap}

%\usepackage{helvet}
%\renewcommand{\familydefault}{\sfdefault}

\usepackage{afterpage}
\usepackage{appendix}
\usepackage{graphicx} % Required for including pictures
\usepackage{listings}

\usepackage[left=2.2cm,top=2.2cm,right=2.2cm,bottom=2.2cm,nohead]{geometry} % Required to change the page size to A4
\geometry{letterpaper} % Set the page size to be A4 as opposed to the default US Letter

\usepackage{float} % Allows putting an [H] in \begin{figure} to specify the exact location of the figure
\usepackage{wrapfig} % Allows in-line images such as the example fish picture


\linespread{1.2} % Line spacing

%\setlength\parindent{0pt} % Uncomment to remove all indentation from paragraphs

\graphicspath{{./Pictures/}} % Specifies the directory where pictures are stored
\usepackage[french,english]{babel}

%Comportement d'un paragraphe
\setlength{\parskip}{\baselineskip}%
\setlength{\parindent}{0pt}%

%Widows/orphans
\widowpenalty10000
\clubpenalty10000

\usepackage[hidelinks]{hyperref}

%Meta-info
\title{INF4500 - examen intra}
\author{Guillaume Lahaie}
\date{Remise: 9 décembre 2013}

\hypersetup{
  pdftitle={INF4500 - examen intra},
  pdfauthor={Guillaume Lahaie}
}

\newcommand\blankpage{%
  \null
  \thispagestyle{empty}%
  \addtocounter{page}{-1}%
  \newpage}

\begin{document}
\selectlanguage{french}

%----------------------------------------------------------------------------------------
%	TITLE PAGE
%----------------------------------------------------------------------------------------

\begin{titlepage}

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}} % Defines a new command for the horizontal lines, change thickness here

\center % Center everything on the page

\textsc{\LARGE Université du Québec à Montréal}\\[1.5cm] % Name of your university/college
\textsc{\Large INF4500}\\[0.5cm] % Major heading such as course name

\HRule \\[1.5cm]
{ \huge \bfseries Examen intra}\\[0.4cm] % Title of your document
\HRule \\[1.5cm]

\begin{minipage}{0.4\textwidth}
\begin{flushleft} \large
\emph{Par:}\\
Guillaume Lahaie \\ LAHG04077707 % Your name
\end{flushleft}
\end{minipage}
~
\begin{minipage}{0.4\textwidth}
\begin{flushright} \large
\emph{Remis à:} \\
Abdoulaye Baniré Diallo % Supervisor's Name
\end{flushright}
\end{minipage}\\[4cm]

{\large \emph{Date de remise:} \\ Le 9 décembre 2013}\\[3cm] % Date, change the \today to a set date if you want to be precise

%\includegraphics{Logo}\\[1cm] % Include a department/university logo - this will require the graphicx package

\vfill % Fill the rest of the page with whitespace

\end{titlepage}
\blankpage

%----------------------------------------------------------------------------------------
%	TABLE OF CONTENTS
%----------------------------------------------------------------------------------------

\tableofcontents % Include a table of contents

\newpage % Begins the essay on a new page instead of on the same page as the table of contents 

%----------------------------------------------------------------------------------------
% SECTIONS DU DOCUMENT
%----------------------------------------------------------------------------------------

\section{Introduction}

Le but de ce travail est d'annoter des contigs du génome du blé. Nous n'avons pas d'information concernant
la provenance de ces contigs, ou même l'espèce exacte de provenance. Afin de pouvoir fournir une information 
pertinente, j'ai tout d'abord recherché ce qui est connu concernant le génome du blé.

J'ai tout d'abord cherché à connaitre l'état d'avancement des travaux de séquençage du blé. Pour ce faire, j'ai consulté
la base de données des génomes de NCBI \cite{Triticum eastivum Genome}. On y apprend des informations de base sur le
génome du blé. On y apprend que le génome du blé a une taille de 16000 Mb distribué en 21 chromosomes. De plus, les chromosomes
ont une forme allohexaploid composée de trois sous-génomes. La nature hexaploid de son génome a ralenti les efforts de séquençage.

Une première référence de génome du blé a été créée avec l'espèce Triticum urartu \cite{Triticum urartu}. Ce génome est toutefois
celui d'un progéniteur du Triticum aestivum, il peut être utile pour aider à améliorer le génome du blé.

On peut obtenir une information plus complète concernant l'avancement du séquençage du Triticum aestivum sur le site du International
Wheat Genome Sequencing Consortium. On y retrouve deux projets parallèles: en premier lieu, un projet de survey sequencing, afin de
produire un contenu de gène potentiel et un ordre de gène virtuel \cite{IWGSC-survey}. Un autre projet en cours est de produire une
séquence de référence pour le génome du Triticum aestivum \cite{IWGSC-reference}. Ce projet semble être à ses débuts, car il semble
être en cours d'obtention de financement.

D'autres bases de données offrent de l'information à propos du génome du blé, par exemple CerealsDB \cite{cerealsDB}, ayant un génome
de travail du blé. Il y a aussi beaucoup d'autres projets, considérant la place importante occupée par le blé dans l'agriculture moderne.

Basé sur ces informations, j'ai décidé de concentrer mes recherches pour l'annotation des contigs fournis sur les données déjà
connues du génome du blé. Je vais donc seulement garder les résultats de Blast provenant du Triticum aestivum. Bien sûr, il s'agit
ici d'une première étape de recherche, il serait ensuite possible d'élargir la recherche pour identifier des zones fonctionnelles possibles
des contigs, ce qui ne sera pas fait dans ce travail.


\newpage
\section{Produisez une analyse sommaire de ces contigs en présentant la distribution des tailles et taux de GC} % Major section

Afin de compiler et de représenter la taille et le taux de GC des contigs produits par
CAP3, j'ai écrit un script python (question1.py) permettant d'extraire les informations du
fichier seq.data.cap.contigs. Le fichier contient 346 contigs.

Le script produit deux types de graphiques, à l'aide de gnuplot. Le premier type est un
histogramme, un pour la taille des contigs, et un pour le taux de GC des contigs. On peut
alors remarquer la distribution de ces valeurs. Voici les deux histogrammes:
\begin{figure}[p]
\centering
\includegraphics[scale=0.6,angle=270]{question_1/histogramme_taille.eps}
\caption{Histogramme de la taille des contigs}
\includegraphics[scale=0.6,angle=270]{question_1/histogramme_taux.eps}
\caption{Histogramme du taux de GC des contigs}
\end{figure}

J'ai ensuite produit deux graphiques permettant de visualiser différemment ces résultats. On peut
y retrouver la moyenne de taille, la moyenne de taux de GC, ainsi que les contigs se situant en
haut ou en bas ce cette moyenne. On peut aussi voir les valeurs exactes dans le tableau en annexe \ref{1}

La taille moyenne des 346 contigs est de 109 nucléotides, avec un taux de GC moyen de 42,96\%. Ce taux semble
indiquer une prépondérance de région non-codante dans les contigs, car généralement les séquences codantes ont
un taux de GC supérieur aux séquences non-codantes \cite{Wikipedia-GC}.

\begin{figure}[p]
\centering
\includegraphics[scale=0.6,angle=270]{question_1/contigs_taille.eps}
\caption{Nuage de points de la taille des contigs}
\includegraphics[scale=0.6,angle=270]{question_1/contigs_taux.eps}
\caption{Nuage de points du taux de GC des contigs}
\end{figure}


%----------------------------------------------------------------------------------------
% SECTIONS DU DOCUMENT
%----------------------------------------------------------------------------------------
\newpage
\section{Identifiez les annotations Genbank de ces contigs et présentez les dans une table contenant
les colonnes: contigs, numéros Accession, description, uniref id} % Major section

\subsection{Numéros d'accessions et description}
Pour trouver les annotations Genbank des contigs, j'ai tout d'abord effectué un blast de chaque contig
sur la base de données nr/nt de NCBI \cite{BLAST}. J'ai utilisé le script biopython question2.py pour
effectuer tous les blasts, et enregistrer les résultats.

En examinant les résultats de façon sommaire, on remarque une très grande différence entre la qualité des
résultats. Certains ont des E-value très haute, alors que certains ont des valeurs indiquant un résultat de
haute qualité. On peut s'attendre à cela, considérant la grande variabilité des contigs.

Pour traiter les contigs selon leur taille, je calcule la valeur médiane des E-value pour les contigs plus
petits que la taille moyenne. Je fais le même exercice pour les contigs plus grands que la moyenne. Pour
le moment, je m'intéresse au meilleur résultat obtenu seulement pour la médiane.

Comme mentionné en introduction, comme cette analyse s'intéresse seulement au contigs ayant des résultats
pour le Triticum, je ne considère pas dans mes résultats les valeurs de blast pour des espèces différentes
du blé. Je prends donc, dans les résultats de blast, le premier correspondant à un match avec le blé.

J'ai enregistré les résultats dans les fichiers evalue\_lower.txt et evalue\_higher.txt, à l'aide du script
q2\_meanEvalue.py. On peut remarquer que la grande majorité des résultats  obtenus ont des E-values de bonne
qualité, avec un ordre de grandeur permettant d'avoir une grande confiance dans le hit. Basé sur ces données,
je garderai donc tous les résultats, peu importe la taille du contig, ayant une E-value plus petite que 0.01.

Afin d'obtenir les données de numéro d'accession, j'ai modifié le script précédent pour créer un fichier associant
le numéro du contig avec le hit gardé (pour le moment, je garde seulement le premier hit de blé du résultat), avec
le numéro d'accession et la description du hit. Ces données sont gardées seulement si le hit correspond aux
exigences de E-value et de description de hit.

\subsection{Uniref}

Pour obtenir un Uniref \cite{Uniref} pour les contigs retenus, j'ai ensuite utilisé le module bioservices de python permettant
de se connecter au service idmapping de uniprot, pour trouver les identifiants uniref des contigs conservés.

Des 223 contigs restant, 113 ont obtenu des résultats de mapping. Avant de sortir les résultats, j'ai vérifié
le format des données obtenues par ce mapping. Pour certains contigs, un seul résultat est obtenu, alors que
pour certains, on obtient plusieurs mappings différents. Les fichiers XML ne comprennent aucune information
concernant le meilleur résultat, toutefois le service REST utilisé pour le mapping demande de trier les
résultats selon le meilleur score.

Afin de vérifier le résultat, j'ai tenté de blaster un des contigs directement sur la base de données Uniref100,
sur le site \url{http://www.uniprot.org}. Le résultat a été surprenant. J'ai utilisé le contig 2 comme essai,
et le blastx sur Uniref100 n'a retourné aucun hit. Afin de confirmer ce résultat, j'ai effectué le même blastx
en utilisant le service d'EBI et en blastant sur toutes les bases de données de protéines de uniprot. J'ai obtenu
le même résultat.

Je crois que ce résutat est dû au mécanisme de mapping. Comme nous avons pu le constater à la questions 1,
la plupart des contigs donnés ont une longueur moyenne de 109 nucléotides. Toutefois, le numéro d'accession
donnée pour effectuer le id mapping peut correspondre à une très longue séquence. C'est le cas du numéro
d'accession pour le contig 2, il s'agit en fait d'un chromosome complet du blé, ce qui explique les nombreux
résultats du mapping.

J'ai donc décidé de procéder différemment pour obtenir les identifiants uniref correspondant spécifiquement au contig.
J'ai effectué un blastx directement sur la base de données uniref100 pour chaque contig. Pour ce faire, j'ai utilisé
le script q2\_ebi.py. Encore une fois, j'ai utilisé le module bioservices de python pour cette tâche.

J'ai ensuite vérifier les résultats des blasts pour les contigs retenus précédemment. J'ai appliqué le même
filtre: je vérifie tout d'abord si la description du résultat est pour le blé, et ensuite si le E-value 
correspond à une valeur acceptable. Je prends la même valeur que pour les numéros d'accession genbank: 0.01.

Après avoir appliqué ce filtre, il me reste 70 contigs pour lesquels j'ai un numéro d'accession genbank et
un numéro uniref.

\subsection{Construction du tableau}

Comme j'utilise latex pour la rédaction de mon rapport, j'ai écrit un script afin de combiner les informations
de mes différents scripts dans un tableau que je peux insérer directement dans mon fichier latex (q2\_tableau.py).

Le tableau créé rassemble les informations des 223 contigs ayant un résultat de blast pour le blé. Les informations
pour les autres contigs n'est pas présenté. Pour ces contigs, j'indique aussi le uniref trouvé, si une valeur
correspondante existe.

\input{question_2/contigs_q2.tex}

%----------------------------------------------------------------------------------------
% SECTIONS DU DOCUMENT
%----------------------------------------------------------------------------------------
 
\section{Identifiez les contigs qui corderaient pour des protéines et donnez une table de ceux-ci,
contenant contig, numéros d'Accession, Uniref, séquences protéiques} % Major section

Pour identifier les contigs qui coderaient en protéines, j'ai éxaminé de nouveau les résultats de 
blast choisis en numéro 2. Je vais chercher la position des hits dans les résultats retenus, pour
ensuite vérifier dans les fichiers genbank si ces hits correspondent à une région codante d'un gène.

Tout d'abord, j'ai créé un script biopython permettant d'extraire les régions des hits pour le résultat
choisi à la question précédente (q3\_hits.py). Comme certains hits contiennent plusieurs séquences
différentes, j'ai gardé chaque partie du résultat ayant un E-value plus petit que 0.01. Les résultats
de ce script sont enregistrés dans le fichier hit\_locations.txt.


J'ai ensuite vérifié si ces hits correspondent à une région codante dans les fichiers genbank obtenus
à la question précédente. Pour ce faire, j'ai utilisé le script getCDS.py. Après un premier essai,
55 contigs des 223 restants feraient partie d'une région codante. Toutefois, pour 2 des résultats, la
région codante trouvée ne contient pas d'information à propos de la séquence protéique obtenue. Par exemple,
pour le contig 120, le CDS observé indique que la région codante correspond à un pseudogène qui n'est pas
encore identifié.

Ce résultat est étonnant aussi car le blast des contigs sur la base de données Uniref100 a trouvé 70 résultats, donc
on devrait s'attendre à un résultat similaire. 

J'ai essayé d'autres approches afin d'identifier les gènes qui coderaient pour les protéines. J'ai tenté de faire des
blastx des contigs sur chaque contig retenu à la question précédente, toutefois j'ai rencontré des problèmes techniques
lors des blasts. Certains blasts prenaient trop de temps à effectuer, et NCBI retournait un message d'erreur.
J'ai utilisé le script python q3\_blastx.py pour tenter cette approche.

Finalement, j'ai préféré utilisé les résultats de la question précédente pour identifier les contigs qui coderaient
pour des protéines. Comme j'ai déjà fait un blastx sur la base de données Uniref100, je considère donc que les contigs
qui rencontrent les critères pour les résultats du blast à la question précédente sont ceux qui coderaient pour des
protéines.

Dans le tableau des réstultats, la séquence protéique donnée est celle correspondante au hit obtenu de blastx. Donc, 
la séquence représentée est seulement une partie de la séquence représentative du cluster identifié par l'identifiant
Uniref. Il serait possible de convertir l'identifiant uniref en identifiant Uniprot afin d'obtenir la séquence complète.




%----------------------------------------------------------------------------------------
% SECTIONS DU DOCUMENT
%----------------------------------------------------------------------------------------

\section{Question 4} % Major section

\subsection[Alignement multiple]{Alignez ces CDS en utilisant ClustalW, dialign et Mavid}


\subsection[Facilité et rapidité des programmes]{Discutez de la performance en terme de facilité
d'utilisation et de rapidité des différents programmes.}

\subsection[Qualité des alignements]{Analysez et discutez de la qualité de l'alignement donné par chaque méthode.}

\subsection[Meilleur alignement]{Quel est votre meilleur alignement? Justifiez votre choix.}

\begingroup
\renewcommand{\appendix}{%
    \renewcommand{\thesubsection}{\arabic{subsection}}
}

\newpage
\appendix
\section{Annexes}

\subsection{Tableau de la taille et du taux de GC des contigs}\label{1}

\footnotesize{
\begin{longtable}{|p{2cm}|p{2cm}|p{2cm}|p{2cm}|p{2cm}|p{2cm}|}
\hline
Contig & Taille & Taux GC & Contig & Taille & Taux GC\\
\hline
1 & 91& 51.65 & 2 & 182& 31.87\\
\hline
3 & 183& 42.62 & 4 & 103& 39.81\\
\hline
5 & 83& 42.17 & 6 & 90& 42.22\\
\hline
7 & 100& 46.00 & 8 & 88& 38.64\\
\hline
9 & 122& 33.61 & 10 & 110& 37.27\\
\hline
11 & 140& 43.57 & 12 & 96& 37.50\\
\hline
13 & 120& 37.50 & 14 & 114& 39.47\\
\hline
15 & 79& 64.56 & 16 & 238& 41.60\\
\hline
17 & 143& 55.24 & 18 & 97& 51.55\\
\hline
19 & 143& 53.85 & 20 & 82& 45.12\\
\hline
21 & 209& 45.45 & 22 & 105& 38.10\\
\hline
23 & 150& 48.67 & 24 & 102& 47.06\\
\hline
25 & 101& 36.63 & 26 & 88& 43.18\\
\hline
27 & 151& 35.76 & 28 & 137& 59.85\\
\hline
29 & 97& 44.33 & 30 & 112& 25.89\\
\hline
31 & 70& 38.57 & 32 & 125& 44.80\\
\hline
33 & 83& 40.96 & 34 & 95& 32.63\\
\hline
35 & 201& 38.31 & 36 & 203& 30.05\\
\hline
37 & 69& 79.71 & 38 & 153& 36.60\\
\hline
39 & 75& 44.00 & 40 & 96& 46.88\\
\hline
41 & 52& 44.23 & 42 & 74& 45.95\\
\hline
43 & 96& 63.54 & 44 & 115& 43.48\\
\hline
45 & 87& 44.83 & 46 & 96& 48.96\\
\hline
47 & 82& 45.12 & 48 & 125& 40.00\\
\hline
49 & 131& 35.88 & 50 & 102& 49.02\\
\hline
51 & 70& 47.14 & 52 & 80& 43.75\\
\hline
53 & 99& 42.42 & 54 & 124& 40.32\\
\hline
55 & 108& 45.37 & 56 & 142& 40.85\\
\hline
57 & 87& 36.78 & 58 & 133& 40.60\\
\hline
59 & 112& 33.04 & 60 & 90& 40.00\\
\hline
61 & 94& 44.68 & 62 & 95& 44.21\\
\hline
63 & 103& 44.66 & 64 & 185& 59.46\\
\hline
65 & 142& 41.55 & 66 & 99& 40.40\\
\hline
67 & 150& 49.33 & 68 & 84& 34.52\\
\hline
69 & 46& 50.00 & 70 & 110& 34.55\\
\hline
71 & 80& 47.50 & 72 & 134& 50.00\\
\hline
73 & 113& 53.10 & 74 & 93& 45.16\\
\hline
75 & 179& 36.87 & 76 & 82& 46.34\\
\hline
77 & 106& 42.45 & 78 & 61& 45.90\\
\hline
79 & 157& 31.21 & 80 & 111& 69.37\\
\hline
81 & 92& 47.83 & 82 & 183& 45.90\\
\hline
83 & 51& 39.22 & 84 & 143& 34.97\\
\hline
85 & 87& 40.23 & 86 & 102& 62.75\\
\hline
87 & 51& 29.41 & 88 & 116& 46.55\\
\hline
89 & 107& 42.99 & 90 & 76& 46.05\\
\hline
91 & 73& 47.95 & 92 & 104& 36.54\\
\hline
93 & 201& 45.27 & 94 & 85& 31.76\\
\hline
95 & 99& 41.41 & 96 & 108& 38.89\\
\hline
97 & 63& 33.33 & 98 & 131& 45.80\\
\hline
99 & 62& 25.81 & 100 & 111& 40.54\\
\hline
101 & 121& 38.84 & 102 & 109& 43.12\\
\hline
103 & 70& 37.14 & 104 & 148& 43.92\\
\hline
105 & 105& 46.67 & 106 & 103& 70.87\\
\hline
107 & 105& 37.14 & 108 & 104& 42.31\\
\hline
109 & 92& 41.30 & 110 & 80& 38.75\\
\hline
111 & 120& 22.50 & 112 & 101& 47.52\\
\hline
113 & 69& 44.93 & 114 & 76& 38.16\\
\hline
115 & 92& 76.09 & 116 & 69& 36.23\\
\hline
117 & 94& 47.87 & 118 & 55& 34.55\\
\hline
119 & 138& 67.39 & 120 & 112& 38.39\\
\hline
121 & 78& 47.44 & 122 & 111& 32.43\\
\hline
123 & 104& 31.73 & 124 & 136& 42.65\\
\hline
125 & 104& 46.15 & 126 & 72& 34.72\\
\hline
127 & 88& 47.73 & 128 & 76& 38.16\\
\hline
129 & 120& 42.50 & 130 & 114& 42.98\\
\hline
131 & 105& 49.52 & 132 & 100& 39.00\\
\hline
133 & 114& 42.11 & 134 & 69& 42.03\\
\hline
135 & 112& 41.07 & 136 & 117& 49.57\\
\hline
137 & 106& 45.28 & 138 & 79& 54.43\\
\hline
139 & 117& 51.28 & 140 & 100& 67.00\\
\hline
141 & 146& 43.15 & 142 & 113& 46.02\\
\hline
143 & 120& 44.17 & 144 & 155& 40.65\\
\hline
145 & 88& 40.91 & 146 & 121& 46.28\\
\hline
147 & 98& 47.96 & 148 & 100& 50.00\\
\hline
149 & 81& 44.44 & 150 & 60& 41.67\\
\hline
151 & 80& 46.25 & 152 & 56& 41.07\\
\hline
153 & 109& 44.04 & 154 & 89& 55.06\\
\hline
155 & 179& 44.69 & 156 & 107& 43.93\\
\hline
157 & 99& 38.38 & 158 & 101& 35.64\\
\hline
159 & 125& 46.40 & 160 & 80& 41.25\\
\hline
161 & 93& 56.99 & 162 & 57& 47.37\\
\hline
163 & 79& 50.63 & 164 & 221& 32.58\\
\hline
165 & 96& 41.67 & 166 & 94& 45.74\\
\hline
167 & 119& 32.77 & 168 & 89& 35.96\\
\hline
169 & 81& 51.85 & 170 & 94& 39.36\\
\hline
171 & 115& 46.09 & 172 & 92& 41.30\\
\hline
173 & 117& 43.59 & 174 & 215& 41.40\\
\hline
175 & 83& 30.12 & 176 & 111& 37.84\\
\hline
177 & 104& 32.69 & 178 & 76& 46.05\\
\hline
179 & 204& 33.82 & 180 & 159& 41.51\\
\hline
181 & 123& 35.77 & 182 & 87& 27.59\\
\hline
183 & 100& 40.00 & 184 & 90& 46.67\\
\hline
185 & 93& 41.94 & 186 & 67& 40.30\\
\hline
187 & 138& 39.13 & 188 & 83& 36.14\\
\hline
189 & 81& 32.10 & 190 & 77& 45.45\\
\hline
191 & 101& 46.53 & 192 & 78& 42.31\\
\hline
193 & 82& 46.34 & 194 & 131& 38.93\\
\hline
195 & 96& 34.38 & 196 & 69& 47.83\\
\hline
197 & 115& 47.83 & 198 & 90& 51.11\\
\hline
199 & 154& 45.45 & 200 & 77& 49.35\\
\hline
201 & 93& 41.94 & 202 & 189& 42.86\\
\hline
203 & 84& 39.29 & 204 & 96& 37.50\\
\hline
205 & 109& 56.88 & 206 & 81& 46.91\\
\hline
207 & 106& 51.89 & 208 & 131& 29.77\\
\hline
209 & 94& 45.74 & 210 & 75& 36.00\\
\hline
211 & 109& 36.70 & 212 & 120& 55.83\\
\hline
213 & 128& 57.03 & 214 & 77& 38.96\\
\hline
215 & 121& 36.36 & 216 & 72& 50.00\\
\hline
217 & 139& 48.20 & 218 & 71& 49.30\\
\hline
219 & 106& 44.34 & 220 & 84& 39.29\\
\hline
221 & 81& 35.80 & 222 & 91& 35.16\\
\hline
223 & 98& 43.88 & 224 & 104& 33.65\\
\hline
225 & 84& 46.43 & 226 & 130& 31.54\\
\hline
227 & 94& 46.81 & 228 & 166& 41.57\\
\hline
229 & 138& 41.30 & 230 & 90& 45.56\\
\hline
231 & 95& 47.37 & 232 & 94& 45.74\\
\hline
233 & 98& 55.10 & 234 & 92& 41.30\\
\hline
235 & 130& 33.08 & 236 & 79& 43.04\\
\hline
237 & 127& 46.46 & 238 & 203& 43.84\\
\hline
239 & 92& 40.22 & 240 & 127& 47.24\\
\hline
241 & 120& 39.17 & 242 & 95& 49.47\\
\hline
243 & 174& 35.06 & 244 & 115& 46.09\\
\hline
245 & 155& 36.13 & 246 & 84& 47.62\\
\hline
247 & 82& 52.44 & 248 & 103& 39.81\\
\hline
249 & 94& 48.94 & 250 & 101& 33.66\\
\hline
251 & 90& 37.78 & 252 & 73& 64.38\\
\hline
253 & 110& 42.73 & 254 & 125& 36.80\\
\hline
255 & 82& 53.66 & 256 & 152& 24.34\\
\hline
257 & 80& 43.75 & 258 & 95& 38.95\\
\hline
259 & 61& 49.18 & 260 & 106& 36.79\\
\hline
261 & 68& 39.71 & 262 & 95& 35.79\\
\hline
263 & 114& 41.23 & 264 & 133& 44.36\\
\hline
265 & 93& 40.86 & 266 & 97& 42.27\\
\hline
267 & 99& 43.43 & 268 & 133& 40.60\\
\hline
269 & 118& 33.90 & 270 & 157& 38.85\\
\hline
271 & 188& 42.55 & 272 & 94& 52.13\\
\hline
273 & 126& 26.98 & 274 & 247& 34.82\\
\hline
275 & 101& 31.68 & 276 & 104& 71.15\\
\hline
277 & 94& 34.04 & 278 & 149& 34.90\\
\hline
279 & 111& 32.43 & 280 & 139& 47.48\\
\hline
281 & 95& 32.63 & 282 & 87& 27.59\\
\hline
283 & 107& 72.90 & 284 & 115& 30.43\\
\hline
285 & 133& 48.87 & 286 & 112& 33.93\\
\hline
287 & 100& 48.00 & 288 & 128& 41.41\\
\hline
289 & 90& 41.11 & 290 & 92& 40.22\\
\hline
291 & 137& 48.18 & 292 & 90& 41.11\\
\hline
293 & 153& 41.83 & 294 & 84& 45.24\\
\hline
295 & 80& 40.00 & 296 & 82& 28.05\\
\hline
297 & 92& 51.09 & 298 & 108& 70.37\\
\hline
299 & 101& 40.59 & 300 & 94& 64.89\\
\hline
301 & 173& 35.26 & 302 & 112& 41.96\\
\hline
303 & 107& 37.38 & 304 & 106& 38.68\\
\hline
305 & 81& 40.74 & 306 & 118& 33.05\\
\hline
307 & 95& 47.37 & 308 & 90& 44.44\\
\hline
309 & 96& 51.04 & 310 & 94& 43.62\\
\hline
311 & 99& 40.40 & 312 & 121& 35.54\\
\hline
313 & 89& 49.44 & 314 & 94& 39.36\\
\hline
315 & 99& 56.57 & 316 & 70& 42.86\\
\hline
317 & 90& 51.11 & 318 & 233& 38.63\\
\hline
319 & 118& 48.31 & 320 & 118& 33.05\\
\hline
321 & 76& 48.68 & 322 & 87& 37.93\\
\hline
323 & 105& 47.62 & 324 & 117& 39.32\\
\hline
325 & 88& 47.73 & 326 & 179& 37.43\\
\hline
327 & 262& 36.64 & 328 & 166& 37.35\\
\hline
329 & 200& 50.00 & 330 & 128& 34.38\\
\hline
331 & 111& 36.94 & 332 & 119& 36.97\\
\hline
333 & 150& 40.00 & 334 & 113& 42.48\\
\hline
335 & 94& 43.62 & 336 & 91& 47.25\\
\hline
337 & 174& 33.33 & 338 & 86& 41.86\\
\hline
339 & 187& 34.76 & 340 & 73& 36.99\\
\hline
341 & 92& 39.13 & 342 & 114& 37.72\\
\hline
343 & 80& 43.75 & 344 & 153& 35.29\\
\hline
345 & 77& 54.55 & 346 & 92& 43.48\\
\hline
\end{longtable}
}
346 contigs, taille moyenne: 109.176300578 Taux GC moyen: 42.9628288283



\subsection{Script biopython de calcul des fréquences nucléotidiques}\label{3}
\begin{lstlisting}[frame=single,numbers=left,language=Python]
# -* coding:utf-8 *-#
from Bio import SeqIO
from Bio.SeqRecord import SeqRecord
handle = open("NC_000002_202564986-202645895.gb", "r")
seq_record = SeqIO.parse(handle, 'gb')
for seq in seq_record:
    dist_a = seq.seq.count("A")
    dist_c = seq.seq.count("C")
    dist_g = seq.seq.count("G")
    dist_t = seq.seq.count("T")
    print "A:  count: " + str(dist_a) + " % = " + \
        str(float(dist_a)/len(seq)*100)
    print "C:  count: " + str(dist_c) + " % = " + \
        str(float(dist_c)/len(seq)*100)
    print "G:  count: " + str(dist_g) + " % = " + \
        str(float(dist_g)/len(seq)*100)
    print "T:  count: " + str(dist_t) + " % = " + \
        str(float(dist_t)/len(seq)*100)
    print "total = " + str(dist_a+dist_c+dist_g+dist_t)
\end{lstlisting}

\subsection{Script biopython Pour choisir 5 contigs au hasard à partir du résulat de CAP3, et d'effectuer
un blast sur ces contigs}\label{7}
\begin{lstlisting}[frame=single,numbers=left,language=Python]
# *- coding:utf-8 -* #
import random
from Bio.Blast import NCBIWWW

contigs = {}
contig_no = None
contig_seq = ""
contig_size = 0

with open("seq.data.cap.contigs", "r") as f:
    for line in f:
        # on regarde d'abord si c'est un contig ou non
        if line[0] == '>':
            if contig_no == None:
                contig_no = int(line[7:])
            if contig_seq != "":
                contigs.update({contig_no:contig_seq})
                contig_seq = ""
                contig_no = int(line[7:])
                contig_size+= 1
        else :
            contig_seq = contig_seq + line.replace("\n","")
    contigs.update({contig_no:contig_seq})
    contig_size +=1

# Maintenant, on a nos contigs, on en choisit 5 au hasard
random_contig = []

#Je m'assure ici de ne pas avoir de doublon
for i in range(5):
    random_c = random.randint(1, contig_size)
    while random_c in random_contig:
        random_c = random.randint(1,contig_size)
    random_contig.append(random_c)

#On blast maintenant les contigs choisis:
for i in random_contig:
    result_handle = NCBIWWW.qblast("blastn", "nr", contigs[i])

    #on enregistre le résultat
    nom_fichier = "blast_contig_" + str(i) + ".xml"
    save_file = open(nom_fichier, "w")
    save_file.write(result_handle.read())
    save_file.close()
    result_handle.close()

print "5 contigs cherchés"
\end{lstlisting}

\subsection{Script Biopython pour obtenir les fichiers d'accession des 10 premiers résultats du blast
pour un contig donné.}\label{14}
\begin{lstlisting}[frame=single,numbers=left,language=Python]
# *- coding:utf-8 -* #

#Parser pour un fichier XML de resultat blast
#Specifique a la question 2 du devoir 1. Je sais
#ici que chaque hit a seulement un hsp, donc en 
#specifiant le # d'accession et le sbjct_start et end,
#j'obtiens ce que je cherche

import sys
import os
from Bio.Blast import NCBIXML
from Bio import SeqIO
from Bio.SeqRecord import SeqRecord
from Bio import Entrez

#On choisit une E-VALUE
E_VALUE_THRESH = 0.04
Entrez.email = "glahaie@gmail.com"
path = "annexes/question_2/"

path_fichier = path + "blast_contig_"+sys.argv[1] + ".xml"

with open(path_fichier) as fichier:
    blast_record = NCBIXML.read(fichier)
    i = 0
    path_result = path + "contig_"+sys.argv[1]+"/"
    if not os.path.exists(path_result):
        os.makedirs(path_result)
    for alignment in blast_record.alignments:
        for hsp in alignment.hsps:
            if hsp.expect < E_VALUE_THRESH:
#On obtient alors le fichier genbank
                handle = Entrez.efetch(db="nucleotide", rettype="gb", 
		  retmode="text", id=alignment.accession, 
		  seq_start=hsp.sbjct_start, seq_stop=hsp.sbjct_end)
                seq_record= SeqIO.read(handle, "gb")
                handle.close()
                nom_fichier = path_result + alignment.accession + ".gb"
                SeqIO.write(seq_record, nom_fichier, "gb")

        i += 1
        if i > 10:
            break
\end{lstlisting}

\subsection{Log de l'exécution de clustalw2.}\label{17}
\begin{verbatim}
 CLUSTAL 2.1 Multiple Sequence Alignments


Sequence format is Pearson
Sequence 1: lcl|XM_518463.3_cdsid_XP_518463.2        2058 bp
Sequence 2: lcl|XM_003833312.1_cdsid_XP_003833360.1  2004 bp
Sequence 3: lcl|XM_004043991.1_cdsid_XP_004044039.1  2004 bp
Sequence 4: lcl|XM_002816867.2_cdsid_XP_002816913.1  2043 bp
Sequence 5: lcl|XM_003266293.1_cdsid_XP_003266341.1  2004 bp
Sequence 6: lcl|XM_005553053.1_cdsid_XP_005553110.1  2004 bp
Sequence 7: lcl|NM_001266091.1_cdsid_NP_001253020.1  2043 bp
Sequence 8: lcl|XM_003922988.1_cdsid_XP_003923037.1  2004 bp
Start of Pairwise alignments
Aligning...

Sequences (1:2) Aligned. Score:  98
Sequences (1:3) Aligned. Score:  97
Sequences (1:4) Aligned. Score:  97
Sequences (1:5) Aligned. Score:  97
Sequences (1:6) Aligned. Score:  96
Sequences (1:7) Aligned. Score:  96
Sequences (1:8) Aligned. Score:  96
Sequences (2:3) Aligned. Score:  99
Sequences (2:4) Aligned. Score:  98
Sequences (2:5) Aligned. Score:  98
Sequences (2:6) Aligned. Score:  97
Sequences (2:7) Aligned. Score:  97
Sequences (2:8) Aligned. Score:  97
Sequences (3:4) Aligned. Score:  98
Sequences (3:5) Aligned. Score:  98
Sequences (3:6) Aligned. Score:  98
Sequences (3:7) Aligned. Score:  97
Sequences (3:8) Aligned. Score:  96
Sequences (4:5) Aligned. Score:  98
Sequences (4:6) Aligned. Score:  98
Sequences (4:7) Aligned. Score:  98
Sequences (4:8) Aligned. Score:  97
Sequences (5:6) Aligned. Score:  98
Sequences (5:7) Aligned. Score:  98
Sequences (5:8) Aligned. Score:  96
Sequences (6:7) Aligned. Score:  99
Sequences (6:8) Aligned. Score:  96
Sequences (7:8) Aligned. Score:  96
Guide tree file created:   [foxp4_ortho.dnd]

There are 7 groups
Start of Multiple Alignment

Aligning...
Group 1: Sequences:   2      Score:37737
Group 2: Sequences:   2      Score:37091
Group 3: Sequences:   3      Score:37148
Group 4: Sequences:   4      Score:37047
Group 5: Sequences:   5      Score:37481
Group 6: Sequences:   7      Score:37220
Group 7: Sequences:   8      Score:36779
Alignment Score 440506

CLUSTAL-Alignment file created  [foxp4_ortho.aln]
\end{verbatim}

\subsection{Log du travail de RepeatMasker sur le fichier foxp4\_ortho.fa.}\label{18}
\begin{verbatim}
There were no repetitive sequences detected in /usr/local/rmserver/tmp/RM2_foxp4_ortho.fa_1383262617
\end{verbatim}

\subsection{Log de l'exécution de Mavid sur foxp4\_ortho.fa.}\label{19}
\begin{verbatim}
./utils/randtree/randtree foxp4_ortho.fa
./mavid ./mavid.ph foxp4_ortho.fa

*******************************************************
*                                                     *
*                  Welcome to MAVID.                  *
*                  (version 2.0, build 4)             *
*                                                     *
*******************************************************


Aligning 1 versus 1
Aligning [0,2003] to [0,2057]
Aligning 1 versus 2
Aligning [0,2003] to [0,2058]
Aligning 1 versus 1
Aligning [0,2003] to [0,2042]
Aligning 1 versus 1
Aligning [0,2003] to [0,2003]
Aligning 1 versus 2
Aligning [0,2042] to [0,2003]
Aligning 2 versus 3
Aligning [0,2042] to [0,2042]
Aligning 3 versus 5
Aligning [0,2058] to [0,2042]
MAVID worked!

clustalw2 ./mavid.mfa -tree



 CLUSTAL 2.1 Multiple Sequence Alignments


Sequence format is Pearson
Sequence 1: lcl|XM_004043991.1_cdsid_XP_004044039.1  2059 bp
Sequence 2: lcl|XM_005553053.1_cdsid_XP_005553110.1  2059 bp
Sequence 3: lcl|XM_518463.3_cdsid_XP_518463.2        2059 bp
Sequence 4: lcl|XM_003266293.1_cdsid_XP_003266341.1  2059 bp
Sequence 5: lcl|NM_001266091.1_cdsid_NP_001253020.1  2059 bp
Sequence 6: lcl|XM_002816867.2_cdsid_XP_002816913.1  2059 bp
Sequence 7: lcl|XM_003833312.1_cdsid_XP_003833360.1  2059 bp
Sequence 8: lcl|XM_003922988.1_cdsid_XP_003923037.1  2059 bp

Phylogenetic tree file created:   [./mavid.ph]

../utils/root_tree/root_tree ./mavid.ph
./mavid ./mavid.ph foxp4_ortho.fa

*******************************************************
*                                                     *
*                  Welcome to MAVID.                  *
*                  (version 2.0, build 4)             *
*                                                     *
*******************************************************


Aligning 1 versus 1
Aligning [0,2003] to [0,2042]
Aligning 1 versus 1
Aligning [0,2057] to [0,2003]
Aligning 1 versus 2
Aligning [0,2003] to [0,2003]
Aligning 3 versus 1
Aligning [0,2003] to [0,2042]
Aligning 1 versus 4
Aligning [0,2003] to [0,2042]
Aligning 2 versus 5
Aligning [0,2042] to [0,2042]
Aligning 1 versus 7
Aligning [0,2003] to [0,2042]
MAVID worked!

clustalw2 ./mavid.mfa -tree



 CLUSTAL 2.1 Multiple Sequence Alignments


Sequence format is Pearson
Sequence 1: lcl|XM_003922988.1_cdsid_XP_003923037.1  2098 bp
Sequence 2: lcl|XM_005553053.1_cdsid_XP_005553110.1  2098 bp
Sequence 3: lcl|NM_001266091.1_cdsid_NP_001253020.1  2098 bp
Sequence 4: lcl|XM_003266293.1_cdsid_XP_003266341.1  2098 bp
Sequence 5: lcl|XM_004043991.1_cdsid_XP_004044039.1  2098 bp
Sequence 6: lcl|XM_518463.3_cdsid_XP_518463.2        2098 bp
Sequence 7: lcl|XM_003833312.1_cdsid_XP_003833360.1  2098 bp
Sequence 8: lcl|XM_002816867.2_cdsid_XP_002816913.1  2098 bp

Phylogenetic tree file created:   [./mavid.ph]

../utils/root_tree/root_tree ./mavid.ph
\end{verbatim}

\subsection{Script biopython pour identifier la composition du vecteur pANNE}\label{23}
\begin{lstlisting}[frame=single,numbers=left,language=Python]
# *- coding:utf-8 -* #

# Script pour le numéro 3 du devoir 1: Cette partie ne fait
#qu'envoyer la requête blast au serveur du NCBI, et ensuite
#enregistre le résultat dans un fichier.

from Bio.Blast import NCBIWWW
from Bio.Blast import NCBIXML

path_fichier = "annexes/question_3/"
nom_resultat = "blast_fichier"
LEN_THRESH = 100
E_THRESH = 1e-50
# Tout d'abord on ouvre le fichier

sequence = ""
with open(path_fichier+"pANNE.txt", 'r') as f:
    for line in f:
        sequence = sequence + line.strip()

#On enlève les retour de chariot du fichier
i = 1
while len(sequence) > LEN_THRESH:

#Maintenant, on fait le blast
    print "i = " + str(i)
    print "on fait un blast sur la séquence de longeur " 
      + str(len(sequence))
    result_handle = NCBIWWW.qblast("blastn", "nr", 
      sequence, megablast=True)

#on enregistre le résultat
    save_file = open(path_fichier+nom_resultat+str(i)+".xml", "w")
    save_file.write(result_handle.read())
    save_file.close()
    result_handle.close()

    list_start = []
    list_end = []
    sequences = []
#Maintenant on enlève de la séquence les zones identifiées
    with open(path_fichier+nom_resultat+str(i)+".xml", "r") as result:
        blast_record = NCBIXML.read(result)
        alignment = blast_record.alignments[0]
        for alignment in blast_record.alignments:
            for hsp in alignment.hsps:
#On met à jour la séquence pour enlever ce résultat
                if hsp.expect < E_THRESH:
                    list_start.append(hsp.query_start)
                    list_end.append(hsp.query_end)
                
            break
#On a les points à enlever
#sort sur les listes
        list_start.sort()
        list_end.sort()
        start= -1
        end = -1
        for s_start, s_end in zip(list_start, list_end):
            if end < 0:
                sequences.append(sequence[: s_start-1])
                end = s_start-1
            else:
                end = s_start-1
                sequences.append(sequence[start: end])
            start = s_end -1
        sequences.append(sequence[start:])
        sequence = ""
        for fragment in sequences:
            sequence +=fragment
#Pour vérifier les résutats, j'enregistre la nouvelle 
#séquence dans un fichier
        print "On écrit le reste de la séquence avec i = " + str(i)
        with open(path_fichier+"pANNE"+str(i)+".txt", "w") as f:
            f.write(sequence)
    i +=1
\end{lstlisting}

\subsection{Temps d'exécution des alignements multiples}\label{24}
\begin{tabular}{|c|c|}
 \hline
 Programme & Temps d'exécution \\
 \hline
 ClustalW & real 0m4.840s \\
 \hline
 dialign & real 0m18.424s \\
 \hline
 Mavid & real 0m0.296s\\
 \hline
\end{tabular}

\subsection{Script Biopython pour obtenir les fichiers d'accession des 10 premiers résultats du blast
pour un contig donné.}\label{25}
\begin{lstlisting}[frame=single,numbers=left,language=Python]
#- coding:utf-8 -#

from reportlab.lib import colors
from reportlab.lib.units import cm
from Bio.Graphics import GenomeDiagram
from Bio.Graphics.GenomeDiagram import CrossLink
from reportlab.lib import colors

gd_diagram = GenomeDiagram.Diagram("Composition du vecteur pANNE.txt")
gd_track_for_features = gd_diagram.new_track(1, name="Annotated Features", 
  start=0, end=6627)
gd_feature_set = gd_track_for_features.new_set()
from Bio.SeqFeature import SeqFeature, FeatureLocation

colors = [colors.green,colors.lightgreen, colors.teal, colors.darkgreen,
  colors.seagreen,colors.lawngreen,colors.olivedrab]

#Essai à la main, à la lecture des fichiers XML
#blast #1: pHT2
feature = SeqFeature(FeatureLocation(1, 1056), strand = +1)
gd_feature_set.add_feature(feature, name="pHT2", label=True, color=colors[0],
  sigil="ARROW", arrowhead_length=0.5,arrowshaft_height=0.1)
feature = SeqFeature(FeatureLocation(5342, 5798), strand = +1)
gd_feature_set.add_feature(feature, name="pHT2", label=True, color=colors[1], 
  sigil="ARROW", arrowhead_length=1,arrowshaft_height=0.1)
feature = SeqFeature(FeatureLocation(3495, 5341), strand = +1)
gd_feature_set.add_feature(feature, name="pHT2", label=True, color=colors[2], 
  sigil="ARROW", arrowhead_length=1,arrowshaft_height=0.1)
feature = SeqFeature(FeatureLocation(5798, 6627), strand = +1)
gd_feature_set.add_feature(feature, name="pHT2", label=True, color=colors[3], 
  sigil="ARROW", arrowhead_length=1,arrowshaft_height=0.1)
feature = SeqFeature(FeatureLocation(3039, 3494), strand = +1)
gd_feature_set.add_feature(feature, name="pHT2", label=True, color=colors[4], 
  sigil="ARROW", arrowhead_length=1,arrowshaft_height=0.1)
feature = SeqFeature(FeatureLocation(1742, 2057), strand = +1)
gd_feature_set.add_feature(feature, name="pHT2", label=True, color=colors[5], 
  sigil="ARROW", arrowhead_length=1,arrowshaft_height=0.1)
feature = SeqFeature(FeatureLocation(2776, 3039), strand = +1)
gd_feature_set.add_feature(feature, name="pHT2", label=True, color=colors[6], 
  sigil="ARROW", arrowhead_length=1,arrowshaft_height=0.1)

#blast 2:
feature = SeqFeature(FeatureLocation(1057, 1741), strand = +1)
gd_feature_set.add_feature(feature, name="PGeneClip", label=True, color="blue", 
  sigil="ARROW", arrowhead_length=1)

#blast 3
feature = SeqFeature(FeatureLocation(2058, 2770), strand = +1)
gd_feature_set.add_feature(feature, name="Cloning vector EN.Cherry", label=True,
  color="red", sigil="ARROW",arrowhead_length=1)

#On essai d'ajouter d'autres track pour représenter la position des blasts
gd_track_for_features = gd_diagram.new_track(1, name="pHT2", start=0, end=4924)
gd_feature_set = gd_track_for_features.new_set()
feature = SeqFeature(FeatureLocation(2246, 4092), strand = None)
gd_feature_set.add_feature(feature, name="pHT2", label=False, color=colors[2], 
  sigil="ARROW", arrowhead_length=0.2,arrowshaft_height=0.1)
feature = SeqFeature(FeatureLocation(1, 1058), strand = None)
gd_feature_set.add_feature(feature, name="pHT2", label=False, color=colors[0],
  sigil="ARROW", arrowhead_length=0.2,arrowshaft_height=0.1)
feature = SeqFeature(FeatureLocation(4093, 4922), strand = +1)
gd_feature_set.add_feature(feature, name="pHT2", label=False, color=colors[3], 
  sigil="ARROW", arrowshaft_height=0.1)
feature = SeqFeature(FeatureLocation(2795, 2339), strand = -1)
gd_feature_set.add_feature(feature, name="pHT2", label=False, color=colors[1], 
  sigil="ARROW", arrowshaft_height=0.1)
feature = SeqFeature(FeatureLocation(2340, 2795), strand = +1)
gd_feature_set.add_feature(feature, name="pHT2", label=False, color=colors[4], 
  sigil="ARROW", arrowshaft_height=0.1)
feature = SeqFeature(FeatureLocation(743, 1058), strand = +1)
gd_feature_set.add_feature(feature, name="pHT2", label=False, color=colors[5], 
  sigil="ARROW", arrowshaft_height=0.1)
feature = SeqFeature(FeatureLocation(1984, 2246), strand = +1)
gd_feature_set.add_feature(feature, name="pHT2", label=False,
  color=colors[6],sigil="ARROW",arrowshaft_height=0.1)

#On essai d'ajouter d'autres track pour représenter la position des blasts
gd_track_for_features = gd_diagram.new_track(1, name="PGeneClip", start=0, 
  end=5267)
gd_feature_set = gd_track_for_features.new_set()
feature = SeqFeature(FeatureLocation(1879, 2563), strand = +1)
gd_feature_set.add_feature(feature, name="PGeneClip", label=False, color="blue", 
  sigil="ARROW", arrowhead_length=1,arrowshaft_height=0.1)

gd_track_for_features = gd_diagram.new_track(1, 
  name="Cloning vector EN.Cherry", start=0, end=10649)
gd_feature_set = gd_track_for_features.new_set()
feature = SeqFeature(FeatureLocation(7102, 7813), strand = +1)
gd_feature_set.add_feature(feature, name="Cloning Vector EN.Cherry", label=False, 
  color="red", sigil="ARROW", arrowhead_length=1,arrowshaft_height=0.1)

gd_diagram.draw(format='linear', pagesize="LETTER", orientation="portrait",
  fragments=1, start=0, end=10649)
gd_diagram.write("GD_labels_default.eps", "eps")
\end{lstlisting}

\subsection{Fichiers genbank utilisés pour ce rapport}\label{26}

 \footnotesize{
\begin{longtable}{|p{4.5cm}|p{3.5cm}|p{4.5cm}|p{3.5cm}|}
\hline
 Nom & Numéro d'accession & Nom & Numéro d'accession\\
 \hline \endhead
 Cloning Vector EN.Cherry, complete sequence & HM771696.1 & PGeneClip hMGFP Vector, complete sequence & AY744386.1 \\
 \hline
 Expression vector pHT2, complete sequence & AY773970.1 & Homo sapiens chromosome 6, GRCh37.p13 Primary Assembly & NC\_000006.11 \\
 \hline 
 SARS coronavirus MA15 ExoN1 isolate d3om5, complete genome & JF292906.1 & SARS coronavirus MA15 isolate d2ym4, complete genome & JF292909.1 \\
 \hline
  SARS coronavirus MA15 isolate d4ym5, complete genome & JF292915.1 & SARS coronavirus HKU-39849 isolate recSARS-CoV HKU-39849, 
  complete genome & JN854286 .1 \\
 \hline
   SARS coronavirus HKU-39849 isolate UOB, complete genome & JQ316196.1 & SARS coronavirus isolate Tor2/FP1-10912, complete genome & JX163923.1 \\
 \hline
 SARS coronavirus isolate Tor2/FP1-10851, complete genome & JX163924.1  & SARS coronavirus isolate Tor2/FP1-10895, complete genome & JX163925.1 \\
 \hline
  SARS coronavirus isolate Tor2/FP1-10912, complete genome & JX163926.1  & SARS coronavirus isolate Tor2/FP1-10851, complete genome & JX163927.1 \\
 \hline
   SARS coronavirus isolate Tor2/FP1-10895, complete genome & JX163928.1  & SARS coronavirus SinP3, complete genome & AY559090.1 \\
 \hline
  SARS coronavirus HKU-39849 isolate TCVSP-HARROD-00001, complete genome & GU553363.1  & SARS coronavirus HKU-39849 isolate recSARS-CoV HKU-39849, complete genome & JN854286.1 \\
 \hline
  SARS coronavirus HKU-39849 isolate TCVSP-HARROD-00002, complete genome & GU553364.1  & SARS coronavirus HKU-39849 isolate TCVSP-HARROD-00003, complete genome & GU553365.1 \\
 \hline
  SARS coronavirus Sin850, complete genome & AY559096.1  & SARS coronavirus MA15 isolate P3pp3, complete genome & FJ882948.1 \\
 \hline
  SARS coronavirus MA15 ExoN1 isolate P3pp3, complete genome & FJ882951.1  & SARS coronavirus MA15 isolate P3pp4, complete genome & FJ882952.1 \\
 \hline
  SARS coronavirus MA15, complete genome & FJ882957.1   & SARS coronavirus MA15 isolate P3pp7, complete genome & FJ882958.1 \\
 \hline
  SARS coronavirus MA15 ExoN1 isolate P3pp6, complete genome & FJ882959.1   & SARS coronavirus MA15 isolate P3pp5, complete genome & FJ882961.1 \\
 \hline
   SARS coronavirus ExoN1 isolate c5P1, complete genome & JF292922.1   & SARS coronavirus ExoN1 isolate c5P10, complete genome & JX162087.1 \\
 \hline
 SARS coronavirus ExoN1 strain & KF514407.1   &  PREDICTED: Pan troglodytes forkhead box P4, transcript variant 2 (FOXP4), mRNA & XM\_518463.3  \\
 \hline
  PREDICTED: Pan paniscus forkhead box P4, transcript variant 2 (FOXP4), mRNA. & XM\_003833312.1 & PPREDICTED: Gorilla gorilla gorilla forkhead box P4, transcript variant 2 (FOXP4), mRNA. & XM\_004043991.1  \\
 \hline
   PREDICTED: Pongo abelii forkhead box P4, transcript variant 1 (FOXP4), mRNA. & XM\_002816867.2 & PREDICTED: Nomascus leucogenys forkhead box P4, transcript variant 2 (FOXP4), mRNA. & XM\_003266293.1  \\
 \hline
  PREDICTED: Macaca fascicularis forkhead box P4 (FOXP4), transcript variant X3, mRNA. & XM\_005553053.1 & Macaca mulatta forkhead box P4 (FOXP4), mRNA. & NM\_001266091.1  \\
 \hline
   PREDICTED: Saimiri boliviensis boliviensis forkhead box P4, transcript variant 2 (FOXP4), mRNA & XM\_003922988.1 &  Homo sapiens chromosome 2, GRCh37.p13 Primary Assembly &  NC\_000002.11 \\
 \hline
   Homo sapiens amyotrophic lateral sclerosis 2 (juvenile) (ALS2), transcript variant 1, mRNA & NM\_020919.3 &  Homo sapiens amyotrophic lateral sclerosis 2 (juvenile) (ALS2), transcript variant 2, mRNA &  NM\_001135745.1 \\
 \hline
  Pan troglodytes chromosome 2B, Pan\_troglodytes-2.1.4 & NC\_006470.3 &  Macaca mulatta chromosome 12, Mmul\_051212, whole genome shotgun sequence &  NC\_007869.1 \\
 \hline
   Canis lupus familiaris breed boxer chromosome 37, CanFam3.1, whole genome shotgun sequence & NC\_006619.3 &  Bos taurus breed Hereford chromosome 2, Bos\_taurus\_UMD\_3.1, whole genome shotgun sequence &  AC\_000159.1 \\
 \hline
    Mus musculus strain C57BL/6J chromosome 1, GRCm38.p1 C57BL/6J & NC\_000067.6 &  Rattus norvegicus strain BN/SsNHsdMCW chromosome 9, Rnor\_5.0 &  NC\_005108.3 \\
 \hline
  Gallus gallus isolate \#256 breed Red Jungle fowl, inbred line UCD001 chromosome 7, Gallus\_gallus-4.0, whole genome shotgun sequence & NC\_006094.3 &  Danio rerio strain Tuebingen chromosome 6, Zv9 &  NC\_007117.5 \\
 \hline
 Homo sapiens chromosome 2 genomic contig, GRCh37.p13 Primary Assembly & NT\_005403.17 &  alsin isoform 1 [Homo sapiens] & NP\_065970.2 \\
 \hline
  alsin [Pan troglodytes] & NP\_001073389.1 &  forkhead box protein P4 isoform 1 [Homo sapiens] & NP\_001012426.1 \\
 \hline
\end{longtable}
}

\subsection{Fichiers de gène de NCBI utilisé pour ce rapport}\label{27}

 \footnotesize{
\begin{longtable}{|p{4.5cm}|p{3.5cm}|p{4.5cm}|p{3.5cm}|}
\hline
 Nom & Gene ID & Nom & Gene ID\\
 \hline \endhead
 ALS2 amyotrophic lateral sclerosis 2 (juvenile) [ Homo sapiens (human) ]  & 57679 & ALS2 amyotrophic lateral sclerosis 2 (juvenile) [ Pan troglodytes (chimpanzee) ]  & 470613 \\
 \hline
 ALS2 amyotrophic lateral sclerosis 2 (juvenile) [ Macaca mulatta (Rhesus monkey) ] & 703263 & ALS2 amyotrophic lateral sclerosis 2 (juvenile) [ Canis lupus familiaris (dog) ] & 100856109 \\
 \hline
  ALS2 amyotrophic lateral sclerosis 2 (juvenile) [ Bos taurus (cattle) ]  & 535750 & Als2 amyotrophic lateral sclerosis 2 (juvenile) [ Mus musculus (house mouse) ] & 74018 \\
 \hline
   Als2 amyotrophic lateral sclerosis 2 (juvenile) [ Rattus norvegicus (Norway rat) ]  & 363235 & FOXP4 forkhead box P4 [ Homo sapiens (human) ] & 116113 \\
 \hline
 \end{longtable}
 }
\endgroup

%
%Bibiographie
%
\begin{thebibliography}{99}
{\small
\bibitem{Triticum eastivum Genome}
Triticum aestivum (ID 11) - Genome - NCBI (2013). Retrieved December 17, 2013 from http://www.ncbi.nlm.nih.gov/genome/11.
\bibitem{Triticum urartu}
Ling HQ, Zhao S, Liu D, Wang J, Sun H, Zhang C, Fan H, Li D, Dong L, Tao Y, et al. Draft genome of the wheat A-genome progenitor Triticum
urartu. Nature. 2013 Apr 4;496(7443):87-90. doi: 10.1038/nature11997. Epub 2013 Mar 24. PubMed PMID: 23535596. 
\bibitem{IWGSC-survey}
Whole Chromosome Survey Sequencing (2013). Retrieved December 17, 2013 from http://www.wheatgenome.org/Projects/IWGSC-Bread-Wheat-
Projects/Sequencing/Whole-Chromosome-Survey-Sequencing
\bibitem{IWGSC-reference}
Sequencing Projects (2013). Retrieved December 17, 2013 from http://www.wheatgenome.org/Projects/IWGSC-Bread-Wheat-Projects/Sequencing
\bibitem{cerealsDB}
Wilkinson, P.A., Winfield, M.O., Barker, G.L.A., Allen, A.M., Burridge, A, Coghill, J.A., Burridge, A. and Edwards, K.J. 2012. CerealsDB 2.0:
an integrated resource for plant breeders and scientists. BMC Bioinformatics 13: 219.
\bibitem{Wikipedia-GC}
  GC content. In Wikipedia. Retrieved December 17, 2013, from
  \url{http://en.wikipedia.org/wiki/GC-content}

\bibitem{UCSC genome browser}
    Kent WJ, Sugnet CW, Furey TS, Roskin KM, Pringle TH, Zahler AM, Haussler D. The human genome browser at UCSC. 
    \emph{Genome Res.} 2002 Jun;12(6):996-1006. 
\bibitem{BLAST}
  Basic Local Alignment Search Tool (Altschul et al., J Mol Biol 215:403-410; 1990).
}
\bibitem{Uniref}
Suzek BE, Huang H, McGarvey P, Mazumder R, Wu CH. UniRef: comprehensive and non-redundant UniProt reference clusters. Bioinformatics. 2007 May 15;23(10):1282-8. Epub 2007 Mar 22. PubMed PMID: 17379688. 
\end{thebibliography}

\end{document}